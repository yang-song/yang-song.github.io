<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Yang Song</title> <meta name="author" content="Yang Song"/> <meta name="description" content="The personal website of Yang Song. "/> <meta name="keywords" content="Yang Song, machine learning, AI, artificial intelligence"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/caltech.ico"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://yang-song.net/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <article> <div class="row"> <div class="col-sm-3"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/profile-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/profile-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/profile-1400.webp"></source> <img src="/assets/img/profile.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="profile.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-9"> <h1 class="post-title"> Yang Song (宋飏) </h1> <p class="desc"><br> <strong> Research Principal </strong> <br> <strong> Meta Superintelligence Labs (MSL) </strong> <br><br><br> </p> <div class="social"> <div class="contact-icons"> <a href="mailto:%74%68%75%73%6F%6E%67%79%61%6E%67@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=o_J2CroAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/yang-song" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/yang-song-machine-learning" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/DrYangSong" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a> </div> </div> </div> </div> <div class="clearfix"> <p>I am the Research Principal at Meta Superintelligence Labs, co-leading overall research with Chief Scientist <a href="https://scholar.google.com/citations?user=bMoauM4AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Shengjia Zhao</a>.</p> <p><strong>Previously:</strong> I led the strategic explorations team at OpenAI. I received my Ph.D. in Computer Science from <a href="https://www.stanford.edu" target="_blank" rel="noopener noreferrer">Stanford University</a>, advised by <a href="https://cs.stanford.edu/~ermon" target="_blank" rel="noopener noreferrer">Stefano Ermon</a>. During my PhD, I invented many foundational concepts and techniques in (score-based) diffusion models, for which you can find more in a <a href="/blog/2021/score/">blog post</a>, a <a href="https://www.quantamagazine.org/the-physics-principle-that-inspired-modern-ai-art-20230105/" target="_blank" rel="noopener noreferrer">quanta magazine article</a>, or a recent <a href="https://x.com/slaterstich/status/1911817486439461009" target="_blank" rel="noopener noreferrer">interview</a>. I was a research intern at <a href="https://research.google/teams/brain/" target="_blank" rel="noopener noreferrer">Google Brain</a>, Uber ATG, and <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/" target="_blank" rel="noopener noreferrer">Microsoft Research</a>. I obtained my Bachelor’s degree in Mathematics and Physics from <a href="https://www.tsinghua.edu.cn/" target="_blank" rel="noopener noreferrer">Tsinghua University</a>, where I worked with <a href="http://ml.cs.tsinghua.edu.cn/~jun/index.shtml" target="_blank" rel="noopener noreferrer">Jun Zhu</a>, <a href="http://www.cs.toronto.edu/~urtasun/" target="_blank" rel="noopener noreferrer">Raquel Urtasun</a>, and <a href="http://www.cs.toronto.edu/~zemel/inquiry/home.php" target="_blank" rel="noopener noreferrer">Richard Zemel</a>.</p> </div> <div class="publications"> <h2>selected publications <a href="publications/">[full list]</a> </h2> (*) denotes equal contribution <br> <br> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICLR</abbr><span class="award badge">Oral</span> </div> <div id="lu2024consistency" class="col-sm-9"> <div class="title">Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models</div> <div class="author"> Cheng Lu, and <em>Yang Song</em> </div> <div class="periodical"> <em>In the 13th International Conference on Learning Representations, 2025.</em> </div> <span class="honor"> Oral Presentation [Top 1.8%] </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2410.11081" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Blog</a> <a href="/assets/pdf/ICLR2025/scm_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Consistency models (CMs) are a powerful class of diffusion-based generative models optimized for fast sampling. Most existing CMs are trained using discretized timesteps, which introduce additional hyperparameters and are prone to discretization errors. While continuous-time formulations can mitigate these issues, their success has been limited by training instability. To address this, we propose a simplified theoretical framework that unifies previous parameterizations of diffusion models and CMs, identifying the root causes of instability. Based on this analysis, we introduce key improvements in diffusion process parameterization, network architecture, and training objectives. These changes enable us to train continuous-time CMs at an unprecedented scale, reaching 1.5B parameters on ImageNet 512x512. Our proposed training algorithm, using only two sampling steps, achieves FID scores of 2.06 on CIFAR-10, 1.48 on ImageNet 64x64, and 1.88 on ImageNet 512x512, narrowing the gap in FID scores with the best existing diffusion models to within 10%.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICLR</abbr><span class="award badge">Oral</span> </div> <div id="song2023consistency2" class="col-sm-9"> <div class="title">Improved Techniques for Training Consistency Models</div> <div class="author"> <em>Yang Song</em>, and <a href="https://prafulladhariwal.com/" target="_blank" rel="noopener noreferrer">Prafulla Dhariwal</a> </div> <div class="periodical"> <em>In the 12th International Conference on Learning Representations, 2024.</em> </div> <span class="honor"> Oral Presentation [Top 1.2%] </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2310.14189" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/assets/pdf/ICLR2024/ict.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training. Current consistency models achieve optimal sample quality by distilling from pre-trained diffusion models and employing learned metrics such as LPIPS. However, distillation limits the quality of consistency models to that of the pre-trained diffusion model, and LPIPS causes undesirable bias in evaluation. To tackle these challenges, we present improved techniques for consistency training, where consistency models learn directly from data without distillation. We delve into the theory behind consistency training and identify a previously overlooked flaw, which we address by eliminating Exponential Moving Average from the teacher consistency model. To replace learned metrics like LPIPS, we adopt Pseudo-Huber losses from robust statistics. Additionally, we introduce a lognormal noise schedule for the consistency training objective, and propose to double total discretization steps every set number of training iterations. Combined with better hyperparameter tuning, these modifications enable consistency models to achieve FID scores of 2.51 and 3.25 on CIFAR-10 and ImageNet 64×64 respectively in a single sampling step. These scores mark a 3.5× and 4× improvement compared to prior consistency training approaches. Through two-step sampling, we further reduce FID scores to 2.24 and 2.77 on these two datasets, surpassing those obtained via distillation in both one-step and two-step settings, while narrowing the gap between consistency models and other state-of-the-art generative models.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div> <div id="song2023consistency" class="col-sm-9"> <div class="title">Consistency Models</div> <div class="author"> <em>Yang Song</em>, <a href="https://prafulladhariwal.com/" target="_blank" rel="noopener noreferrer">Prafulla Dhariwal</a>, <a href="https://scholar.google.com/citations?user=5fU-QMwAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Mark Chen</a>, and <a href="https://www.cs.toronto.edu/~ilya/" target="_blank" rel="noopener noreferrer">Ilya Sutskever</a> </div> <div class="periodical"> <em>In the 40th International Conference on Machine Learning, 2023.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2303.01469" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/openai/consistency_models" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/ICML2023/consistency.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://techcrunch.com/2023/04/12/openai-looks-beyond-diffusion-with-consistency-based-image-generator/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Media</a> </div> <div class="abstract hidden"> <p>Diffusion models have made significant breakthroughs in image, audio, and video generation, but they depend on an iterative generation process that causes slow sampling speed and caps their potential for real-time applications. To overcome this limitation, we propose consistency models, a new family of generative models that achieve high sample quality without adversarial training. They support fast one-step generation by design, while still allowing for few-step sampling to trade compute for sample quality. They also support zero-shot data editing, like image inpainting, colorization, and super-resolution, without requiring explicit training on these tasks. Consistency models can be trained either as a way to distill pre-trained diffusion models, or as standalone generative models. Through extensive experiments, we demonstrate that they outperform existing distillation techniques for diffusion models in one- and few-step generation. For example, we achieve the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on ImageNet 64x64 for one-step generation. When trained as standalone generative models, consistency models also outperform single-step, non-adversarial generative models on standard benchmarks like CIFAR-10, ImageNet 64x64 and LSUN 256x256.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Thesis</abbr></div> <div id="song2022learning" class="col-sm-9"> <div class="title">Learning to Generate Data by Estimating Gradients of the Data Distribution</div> <div class="author"> <em>Yang Song</em> </div> <div class="periodical"> <em>Stanford University</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://searchworks.stanford.edu/view/14310542" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Generating realistic data with complex patterns, such as images, audio, or molecular structures, often relies on expressive probabilistic models to represent and estimate high- dimensional data distributions. However, even with the power of deep neural networks, building powerful probabilistic models is non-trivial. One major challenge is the need to normalize probability distributions; that is, to ensure the total probability equals one. This necessitates summing over all possible model outputs, which quickly becomes impractical in high-dimensional spaces. In this dissertation, I propose to address this difficulty by working with data distributions through their score functions. These functions, defined as gradients of log data densities, capture information about the corresponding data distributions without requiring normalization, hence can be modeled with highly flexible deep neural networks. This dissertation is organized into three parts. In Part I, I show how to estimate the score function from a finite dataset with expressive deep neural networks and efficient statistical methods. In Part II, I discuss several ways to generate new data samples from models of score functions, building upon ideas from homotopy methods, Markov chain Monte Carlo, diffusion processes, and differential equations. The resulting score-based generative models (also known as diffusion models) achieved record-breaking generation performance for numerous data modalities, challenging the long-standing dominance of generative adversarial networks on many tasks. Importantly, the sampling procedure of score-based generative models can be flexibly controlled for solving inverse problems, demonstrated by their superior performance on multiple tasks in medical image reconstruction. In Part III, I show how to evaluate probability values accurately with models of score functions. Taken together, score-based generative models provide a flexible, powerful and versatile solution for data generation in machine learning and many other disciplines of science and engineering.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div id="song2022solving" class="col-sm-9"> <div class="title">Solving Inverse Problems in Medical Imaging with Score-Based Generative Models </div> <div class="author"> <em>Yang Song</em>*, Liyue Shen*, <a href="https://med.stanford.edu/xinglab.html" target="_blank" rel="noopener noreferrer">Lei Xing</a>, and <a href="https://cs.stanford.edu/~ermon/" target="_blank" rel="noopener noreferrer">Stefano Ermon</a> </div> <div class="periodical"> <em>In the 10th International Conference on Learning Representations, 2022. Abridged in the NeurIPS 2021 Workshop on Deep Learning and Inverse Problems.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2111.08005" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/yang-song/score_inverse_problems" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p> Reconstructing medical images from partial measurements is an important inverse problem in Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). Existing solutions based on machine learning typically train a model to directly map measurements to medical images, leveraging a training dataset of paired images and measurements. These measurements are typically synthesized from images using a fixed physical model of the measurement process, which hinders the generalization capability of models to unknown measurement processes. To address this issue, we propose a fully unsupervised technique for inverse problem solving, leveraging the recently introduced score-based generative models. Specifically, we first train a score-based generative model on medical images to capture their prior distribution. Given measurements and a physical model of the measurement process at test time, we introduce a sampling method to reconstruct an image consistent with both the prior and the observed measurements. Our method does not assume a fixed measurement process during training, and can thus be flexibly adapted to different measurement processes at test time. Empirically, we observe comparable or better performance to supervised learning techniques in several medical imaging tasks in CT and MRI, while demonstrating significantly better generalization to unknown measurement processes. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr><span class="award badge">Spotlight</span> </div> <div id="song2021mle" class="col-sm-9"> <div class="title">Maximum Likelihood Training of Score-Based Diffusion Models</div> <div class="author"> <em>Yang Song</em>*, Conor Durkan*, <a href="https://homepages.inf.ed.ac.uk/imurray2/" target="_blank" rel="noopener noreferrer">Iain Murray</a>, and <a href="https://cs.stanford.edu/~ermon/" target="_blank" rel="noopener noreferrer">Stefano Ermon</a> </div> <div class="periodical"> <em>In the 35th Conference on Neural Information Processing Systems, 2021.</em> </div> <span class="honor"> Spotlight Presentation [top 3%] </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2101.09258" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/yang-song/score_flow" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/NeurIPS2021/score_flow.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p> Score-based diffusion models synthesize samples by reversing a stochastic process that diffuses data to noise, and are trained by minimizing a weighted combination of score matching losses. The log-likelihood of score-based diffusion models can be tractably computed through a connection to continuous normalizing flows, but log-likelihood is not directly optimized by the weighted combination of score matching losses. We show that for a specific weighting scheme, the objective upper bounds the negative log-likelihood, thus enabling approximate maximum likelihood training of score-based diffusion models. We empirically observe that maximum likelihood training consistently improves the likelihood of score-based diffusion models across multiple datasets, stochastic processes, and model architectures. Our best models achieve negative log-likelihoods of 2.83 and 3.76 bits/dim on CIFAR-10 and ImageNet 32x32 without any data augmentation, on a par with state-of-the-art autoregressive models on these tasks. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div> <div id="song2021nonlinear" class="col-sm-9"> <div class="title">Accelerating Feedforward Computation via Parallel Nonlinear Equation Solving</div> <div class="author"> <em>Yang Song</em>, Chenlin Meng, <a href="http://www.cs.toronto.edu/~rjliao/" target="_blank" rel="noopener noreferrer">Renjie Liao</a>, and <a href="https://cs.stanford.edu/~ermon/" target="_blank" rel="noopener noreferrer">Stefano Ermon</a> </div> <div class="periodical"> <em>In the 38th International Conference on Machine Learning, 2021.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2002.03629" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/ermongroup/fast_feedforward_computation" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/ICML2021/fast_sampling.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p> Feedforward computation, such as evaluating a neural network or sampling from an autoregressive model, is ubiquitous in machine learning. The sequential nature of feedforward computation, however, requires a strict order of execution and cannot be easily accelerated with parallel computing. To enable parallelization, we frame the task of feedforward computation as solving a system of nonlinear equations. We then propose to find the solution using a Jacobi or Gauss-Seidel fixed-point iteration method, as well as hybrid methods of both. Crucially, Jacobi updates operate independently on each equation and can be executed in parallel. Our method is guaranteed to give exactly the same values as the original feedforward computation with a reduced (or equal) number of parallel iterations, and hence reduced time given sufficient parallel computing power. Experimentally, we demonstrate the effectiveness of our approach in accelerating (i) backpropagation of RNNs; (ii) evaluation of DenseNets; and (iii) autoregressive sampling of MADE and PixelCNN++, with speedup factors between 1.12 and 33 under various settings. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICLR</abbr><span class="award badge">Oral</span><span class="award badge">Award</span> </div> <div id="song2021score" class="col-sm-9"> <div class="title">Score-Based Generative Modeling through Stochastic Differential Equations</div> <div class="author"> <em>Yang Song</em>, <a href="https://scholar.google.com/citations?user=-3zYIjQAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Jascha Sohl-Dickstein</a>, <a href="http://dpkingma.com/" target="_blank" rel="noopener noreferrer">Diederik P. Kingma</a>, <a href="https://scholar.google.com/citations?user=6vghMS0AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Abhishek Kumar</a>, <a href="https://cs.stanford.edu/~ermon/" target="_blank" rel="noopener noreferrer">Stefano Ermon</a>, and <a href="https://scholar.google.com/citations?hl=en&amp;user=i5FMLA4AAAAJ&amp;view_op=list_works" target="_blank" rel="noopener noreferrer">Ben Poole</a> </div> <div class="periodical"> <em>In the 9th International Conference on Learning Representations, 2021.</em> </div> <span class="honor"> Outstanding Paper Award </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2011.13456" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://yang-song.github.io/blog/2021/score/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Blog</a> <a href="https://github.com/yang-song/score_sde" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/ICLR2021/score_sde.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://thegradientpub.substack.com/p/update-2-killer-robots-and-diffusion" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Media</a> </div> <div class="abstract hidden"> <p> Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="song2020improved" class="col-sm-9"> <div class="title">Improved Techniques for Training Score-Based Generative Models</div> <div class="author"> <em>Yang Song</em>, and <a href="https://cs.stanford.edu/~ermon/" target="_blank" rel="noopener noreferrer">Stefano Ermon</a> </div> <div class="periodical"> <em>In the 34th Conference on Neural Information Processing Systems, 2020.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2006.09011" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://yang-song.github.io/blog/2021/score/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Blog</a> <a href="https://github.com/ermongroup/ncsnv2" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/NeurIPS2020/ncsnv2-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p> Score-based generative models can produce high quality image samples comparable to GANs, without requiring adversarial optimization. However, existing training procedures are limited to images of low resolution (typically below 32x32), and can be unstable under some settings. We provide a new theoretical analysis of learning and sampling from score models in high dimensional spaces, explaining existing failure modes and motivating new solutions that generalize across datasets. To enhance stability, we also propose to maintain an exponential moving average of model weights. With these improvements, we can effortlessly scale score-based generative models to images with unprecedented resolutions ranging from 64x64 to 256x256. Our score-based models can generate high-fidelity samples that rival best-in-class GANs on various image datasets, including CelebA, FFHQ, and multiple LSUN categories. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr><span class="award badge">Oral</span> </div> <div id="song2019generative" class="col-sm-9"> <div class="title">Generative Modeling by Estimating Gradients of the Data Distribution</div> <div class="author"> <em>Yang Song</em>, and <a href="https://cs.stanford.edu/~ermon/" target="_blank" rel="noopener noreferrer">Stefano Ermon</a> </div> <div class="periodical"> <em>In the 33rd Conference on Neural Information Processing Systems, 2019.</em> </div> <span class="honor"> Oral Presentation [top 0.5%] </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/1907.05600" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://yang-song.github.io/blog/2021/score/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Blog</a> <a href="https://github.com/ermongroup/ncsn" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/NeurIPS2019/ncsn-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/NeurIPS2019/talk_public.pptx" class="btn btn-sm z-depth-0" role="button">Slides</a> <a href="https://www.youtube.com/watch?v=Oc3X_x1Q1jU" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Media</a> </div> <div class="abstract hidden"> <p> We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. Because gradients might be ill-defined when the data resides on low-dimensional manifolds, we perturb the data with different levels of Gaussian noise and jointly estimate the corresponding scores, i.e., the vector fields of gradients of the perturbed data distribution for all noise levels. For sampling, we propose an annealed Langevin dynamics where we use gradients corresponding to gradually decreasing noise levels as the sampling process gets closer to the data manifold. Our framework allows flexible model architectures, requires no sampling during training or the use of adversarial methods, and provides a learning objective that can be used for principled model comparisons. Our models produce samples comparable to GANs on MNIST, CelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.87 on CIFAR-10. Additionally, we demonstrate that our models learn effective representations via image inpainting experiments. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">UAI</abbr><span class="award badge">Oral</span> </div> <div id="song2019sliced" class="col-sm-9"> <div class="title">Sliced Score Matching: A Scalable Approach to Density and Score Estimation</div> <div class="author"> <em>Yang Song</em>*, Sahaj Garg*, Jiaxin Shi, and <a href="https://cs.stanford.edu/~ermon/" target="_blank" rel="noopener noreferrer">Stefano Ermon</a> </div> <div class="periodical"> <em>In the 35th Conference on Uncertainty in Artificial Intelligence, 2019.</em> </div> <span class="honor"> Oral Presentation [top 8.7%] </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/1905.07088" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://ermongroup.github.io/blog/ssm/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Blog</a> <a href="https://github.com/ermongroup/sliced_score_matching" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p> Score matching is a popular method for estimating unnormalized statistical models. However, it has been so far limited to simple models or low-dimensional data, due to the difficulty of computing the trace of Hessians for log-density functions. We show this difficulty can be mitigated by sliced score matching, a new objective that matches random projections of the original scores. Our objective only involves Hessian-vector products, which can be easily implemented using reverse-mode auto-differentiation. This enables scalable score matching for complex models and higher dimensional data. Theoretically, we prove the consistency and asymptotic normality of sliced score matching. Moreover, we demonstrate that sliced score matching can be used to learn deep score estimators for implicit distributions. In our experiments, we show that sliced score matching greatly outperforms competitors on learning deep energy-based models, and can produce accurate score estimates for applications such as variational inference with implicit distributions and training Wasserstein Auto-Encoders. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="song2018construct" class="col-sm-9"> <div class="title"> Constructing Unrestricted Adversarial Examples with Generative Models </div> <div class="author"> <em>Yang Song</em>, Rui Shu, <a href="http://www.kushman.org/" target="_blank" rel="noopener noreferrer">Nate Kushman</a>, and <a href="https://cs.stanford.edu/~ermon/" target="_blank" rel="noopener noreferrer">Stefano Ermon</a> </div> <div class="periodical"> <em>In the 32nd Conference on Neural Information Processing Systems, 2018.</em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/1805.07894" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/ermongroup/generative_adversary" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/NeurIPS2018/uae-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="https://twitter.com/goodfellow_ian/status/999035763596578816" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Media</a> </div> <div class="abstract hidden"> <p> Adversarial examples are typically constructed by perturbing an existing data point within a small matrix norm, and current defense methods are focused on guarding against this type of attack. In this paper, we propose unrestricted adversarial examples, a new threat model where the attackers are not restricted to small norm-bounded perturbations. Different from perturbation-based attacks, we propose to synthesize unrestricted adversarial examples entirely from scratch using conditional generative models. Specifically, we first train an Auxiliary Classifier Generative Adversarial Network (AC-GAN) to model the class-conditional distribution over data samples. Then, conditioned on a desired class, we search over the AC-GAN latent space to find images that are likely under the generative model and are misclassified by a target classifier. We demonstrate through human evaluation that unrestricted adversarial examples generated this way are legitimate and belong to the desired class. Our empirical results on the MNIST, SVHN, and CelebA datasets show that unrestricted adversarial examples can bypass strong adversarial training and certified defense methods designed for traditional adversarial attacks. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div id="song2018pixeldefend" class="col-sm-9"> <div class="title"> PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples </div> <div class="author"> <em>Yang Song</em>, Taesup Kim, <a href="http://www.nowozin.net/sebastian/" target="_blank" rel="noopener noreferrer">Sebastian Nowozin</a>, <a href="https://cs.stanford.edu/~ermon/" target="_blank" rel="noopener noreferrer">Stefano Ermon</a>, and <a href="http://www.kushman.org/" target="_blank" rel="noopener noreferrer">Nate Kushman</a> </div> <div class="periodical"> <em>In the 6th International Conference on Learning Representations, 2018. </em> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/1710.10766" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/Microsoft/PixelDefend/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/ICLR2018/pixeldefend-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p> Adversarial perturbations of normal images are usually imperceptible to humans, but they can seriously confuse state-of-the-art machine learning models. What makes them so special in the eyes of image classifiers? In this paper, we show empirically that adversarial examples mainly lie in the low probability regions of the training distribution, regardless of attack types and targeted models. Using statistical hypothesis testing, we find that modern neural density models are surprisingly good at detecting imperceptible image perturbations. Based on this discovery, we devised PixelDefend, a new approach that purifies a maliciously perturbed image by moving it back towards the distribution seen in the training data. The purified image is then run through an unmodified classifier, making our method agnostic to both the classifier and the attacking method. As a result, PixelDefend can be used to protect already deployed models and be combined with other model-specific defenses. Experiments show that our method greatly improves resilience across a wide variety of state-of-the-art attacking methods, increasing accuracy on the strongest attack from 63% to 84% for Fashion MNIST and from 32% to 70% for CIFAR-10. </p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Yang Song. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-69768980-1"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-69768980-1");</script> </body> </html>